{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Animations import MoveAnimation\n",
    "from moviepy.editor import ImageSequenceClip, ImageClip, CompositeVideoClip, VideoFileClip, concatenate_videoclips\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_suffix(folder_path, suffix):\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        if os.path.isfile(os.path.join(folder_path, file)):\n",
    "            file_name, file_ext = os.path.splitext(file)\n",
    "            if file_name.endswith(suffix):\n",
    "                new_file_name = file_name[:-len(suffix)] + file_ext\n",
    "                os.rename(os.path.join(folder_path, file), os.path.join(folder_path, new_file_name))\n",
    "\n",
    "# Example usage\n",
    "frame_path = 'images\\\\frames'\n",
    "suffix = '_delay'\n",
    "remove_suffix(frame_path, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having fun with videos editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frames to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_video.mp4.\n",
      "Moviepy - Writing video output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_list = [os.path.join('images\\\\frames', frame) for frame in os.listdir('images\\\\frames')] # your images list\n",
    "clip = ImageSequenceClip(images_list, fps=24)  # fps: frames per second\n",
    "clip.write_videofile(\"output_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video mecquidanse.mp4.\n",
      "Moviepy - Writing video mecquidanse.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready mecquidanse.mp4\n"
     ]
    }
   ],
   "source": [
    "def create_video_from_frames(frame_path, output_video_path, fps):\n",
    "    images_list = [os.path.join(frame_path, frame) for frame in os.listdir(frame_path)]\n",
    "    clip = ImageSequenceClip(images_list, fps=fps)\n",
    "    clip.write_videofile(output_video_path)\n",
    "\n",
    "create_video_from_frames('images\\\\frames', 'mecquidanse.mp4', 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add picture overlay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video my_edited_video.mp4.\n",
      "Moviepy - Writing video my_edited_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready my_edited_video.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_list = [os.path.join('images\\\\frames', frame) for frame in os.listdir('images\\\\frames')]\n",
    "clip = ImageSequenceClip(images_list, fps=20)\n",
    "\n",
    "# Load the image to be added\n",
    "image_clip = ImageClip(\"jai_peur.png\").set_start(0).set_duration(3)\n",
    "\n",
    "# Resize and position the image in the middle of the screen\n",
    "image_clip = image_clip.resize(width=clip.w/2, height=clip.h/2)\n",
    "x = (clip.w - image_clip.w) / 2\n",
    "y = (clip.h - image_clip.h) / 2\n",
    "image_clip = image_clip.set_pos((x, y))\n",
    "\n",
    "# Overlay the image on the video\n",
    "final_clip = CompositeVideoClip([clip, image_clip])\n",
    "\n",
    "# Save the video\n",
    "final_clip.write_videofile(\"my_edited_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image_to_video(input_video_path, output_video_path, image_path, start_time = 0, duration = -1, x_pos = 0, y_pos=0, width=-1, height=-1):\n",
    "    clip = VideoFileClip(input_video_path)\n",
    "\n",
    "    if(duration == -1):\n",
    "        duration = clip.duration - start_time\n",
    "    if(width == -1):\n",
    "        width = clip.w\n",
    "    if(height == -1):\n",
    "        height = clip.h\n",
    "    \n",
    "    \n",
    "\n",
    "    # Split the video into three parts\n",
    "    clip_before = clip.subclip(0, start_time)\n",
    "    clip_middle = clip.subclip(start_time, start_time + duration)\n",
    "    clip_after = clip.subclip(start_time + duration, clip.duration)\n",
    "\n",
    "    image_clip = ImageClip(image_path)\n",
    "    image_clip = image_clip.resize(width=width, height=height)\n",
    "    image_clip = image_clip.set_pos((x_pos, y_pos))\n",
    "\n",
    "    image_clip = image_clip.set_start(0).set_duration(clip_middle.duration)\n",
    "\n",
    "    final_clip_middle = CompositeVideoClip([clip_middle, image_clip])\n",
    "\n",
    "    final_clip = concatenate_videoclips([clip_before, final_clip_middle, clip_after])\n",
    "\n",
    "    # Save the video\n",
    "    final_clip.write_videofile(output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video mecquidanse_with_image.mp4.\n",
      "Moviepy - Writing video mecquidanse_with_image.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready mecquidanse_with_image.mp4\n"
     ]
    }
   ],
   "source": [
    "add_image_to_video('mecquidanse.mp4', 'mecquidanse_with_image.mp4', 'jai_peur.png', 3, 2, 0, 0, 160, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animate Image\n",
    "#### Move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 24.0, duration: 5.25, size: [260, 200]\n"
     ]
    }
   ],
   "source": [
    "danse = VideoFileClip('mecquidanse.mp4')\n",
    "print(f'fps: {danse.fps}, duration: {danse.duration}, size: {danse.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Animations import MoveAnimation\n",
    "\n",
    "def animate_image(input_video_path, output_video_path, image_path, anim: MoveAnimation):\n",
    "    clip = VideoFileClip(input_video_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    if(anim.duration == -1):\n",
    "        anim.duration = clip.duration - anim.start_time\n",
    "    if(anim.start_size == (-1,-1)):\n",
    "        anim.start_size = (clip.w, clip.h)\n",
    "    if(anim.end_size == (-1,-1)):\n",
    "        anim.end_size = (clip.w, clip.h)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Split the video into three parts\n",
    "    clip_before = clip.subclip(0, anim.start_time)\n",
    "    clip_middle = clip.subclip(anim.start_time, anim.start_time + anim.duration)\n",
    "    clip_after = clip.subclip(anim.start_time + anim.duration, clip.duration)\n",
    "\n",
    "    image_clip = ImageClip(image_path)\n",
    "    image_clip.fps = clip.fps\n",
    "    if(anim.start_size == (0,0)):\n",
    "        image_clip = image_clip.resize((1,1))\n",
    "    else: \n",
    "        image_clip = image_clip.resize(anim.start_size)\n",
    "    image_clip = image_clip.set_pos(anim.start_pos)\n",
    "\n",
    "    \n",
    "    image_clip = image_clip.set_start(0).set_duration(clip_middle.duration)\n",
    "\n",
    "    move_func = lambda t: anim.get_pos(t)\n",
    "    image_clip = image_clip.set_position(move_func)\n",
    "    \n",
    "    size_func = lambda t: anim.get_size(t)\n",
    "    image_clip = image_clip.resize(size_func) # if size_func != (0,0) else None\n",
    "    \n",
    "    final_clip_middle = CompositeVideoClip([clip_middle, image_clip])\n",
    "    final_clip = concatenate_videoclips([clip_before, final_clip_middle, clip_after])\n",
    "\n",
    "    # Save the video\n",
    "    final_clip.write_videofile(output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video mecquidanse_with_image.mp4.\n",
      "Moviepy - Writing video mecquidanse_with_image.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready mecquidanse_with_image.mp4\n"
     ]
    }
   ],
   "source": [
    "moveAnim = MoveAnimation(1, 2, (0, 0), (160, 90), end_size=(10, 10))\n",
    "\n",
    "animate_image('mecquidanse.mp4', 'mecquidanse_with_image.mp4', 'jai_peur.png', moveAnim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Images from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find moment from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "def get_description_pictures(story):\n",
    "    api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "    model = \"open-mistral-7b\"\n",
    "\n",
    "    client = MistralClient(api_key=api_key)\n",
    "\n",
    "    preprompt = \"\"\"Your job will be to write the visual of a tiktok video: the images that show on screen. You have to find some nice moments in the story to place pictures that will show on screen. Tell me when you choose an image of what. In this format:\n",
    "    DURING THE SENTENCE \"[place the full sentence here]\", SHOW AN IMAGE OF \"[place the description of the image]\".\n",
    "    Answer only with the descriptions of all the images.\n",
    "    \n",
    "    For example:\n",
    "    DURING THE SENTENCE \"he ate a sandwich\", SHOW AN IMAGE OF \"a sandwich\".\n",
    "\n",
    "    Now it is your turn:\n",
    "\n",
    "    STORY : \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        ChatMessage(role=\"user\", content=preprompt + f'\"{story}\"'),\n",
    "    ]\n",
    "\n",
    "    chat_response = client.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    results = chat_response.choices[0].message.content\n",
    "\n",
    "    return results.split(\"\\n\\n\")\n",
    "def convert_to_dict(lines):\n",
    "    visual_dict = {}\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        if line:\n",
    "            sentence, image_desc = line.split(', SHOW AN IMAGE OF ', 1)\n",
    "            sentence = sentence.replace('DURING THE SENTENCE ', '', 1)\n",
    "            visual_dict[sentence] = image_desc\n",
    "    return visual_dict\n",
    "\n",
    "def get_description_pictures(story):\n",
    "    return convert_to_dict(get_description_pictures(story))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
